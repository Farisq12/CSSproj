{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal of this program is to further detect articles that grover deems as not fake to check if it's fake news with detecting it with keywords and altering it to where Grover would then detect it as fake news**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we should be able to parse the text files whether its .txt or .pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for parsing .txt file\n",
    "def parse_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For pdf make sure to install PyPDF2 using: pip install PyPDF2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for parsing .pdf file\n",
    "import PyPDF2\n",
    "\n",
    "def parse_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfFileReader(file)\n",
    "        num_p = reader.numPages\n",
    "        text = \"\"\n",
    "\n",
    "        for page_num in range(num_p):\n",
    "            page = reader.getPage(page_num)\n",
    "            text += page.extractText()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that parsing functions are made we can preprocess the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Implement your preprocessing function here\n",
    "    preprocessed_text = text.lower()\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates hash key for each word in the text using SHA-256\n",
    "def generate_hash_key(word):\n",
    "    sha256 = hashlib.sha256()\n",
    "    sha256.update(word.encode('utf-8'))\n",
    "    return sha256.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates and stores words and stores them into a hash_table\n",
    "def create_dict(text):\n",
    "    preprocessed_text = preprocess(text)\n",
    "    words = preprocessed_text.split()\n",
    "    hash_table = defaultdict(list)\n",
    "\n",
    "    for word in words:\n",
    "        hash_key = generate_hash_key(word)\n",
    "        hash_table[hash_key].append(word)\n",
    "    return hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs the hash key function to compare old vs new text and if values are not the same returns false\n",
    "def verify_doc(document, hash_table):\n",
    "    preprocessed_document = preprocess(document)\n",
    "    words = preprocessed_document.split()\n",
    "\n",
    "    for word in words:\n",
    "        hash_key = generate_hash_key(word)\n",
    "        if hash_key not in hash_table:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should output false\n",
    "\n",
    "input_text = \"I like apples\"\n",
    "document = \"I like oranges\"\n",
    "\n",
    "hash_table = create_dict(input_text)\n",
    "is_authentic = verify_doc(document, hash_table)\n",
    "\n",
    "print(\"Is the document authentic?\", is_authentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should output True\n",
    "\n",
    "input_text = \"I like bananas\"\n",
    "document = \"I like bananas\"\n",
    "\n",
    "hash_table = create_dict(input_text)\n",
    "is_authentic = verify_doc(document, hash_table)\n",
    "\n",
    "print(\"Is the document authentic?\", is_authentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyFile (file):\n",
    "    if file.lower().endswith('.txt'):\n",
    "        parse_txt(file)\n",
    "    elif file.lower().endswith('.pdf'):\n",
    "        parse_pdf(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "302b62cf748a890b25d1c845d1f31bf6a836a82abe7bc900ffc29ed792cad2fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
